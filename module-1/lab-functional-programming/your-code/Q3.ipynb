{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lambda** is a special Python function type that is **anonymous**. By *anonymous* it means a lambda function does not have name. Lambda functions are embedded inside codes so that you don't call them like calling regular Python functions.\n",
    "\n",
    "**`Map`** applies a function to all the items in an input list. The function that is applied can be a standard or a lambda function.\n",
    "\n",
    "For instance, below is an example of multiplying number tuples in a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 12, 30]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = [(1,2), (3,4), (5,6)]\n",
    "\n",
    "def multiply(num_tuple):\n",
    "    return num_tuple[0]*num_tuple[1]\n",
    "list(map(multiply, items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...is the same as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 12, 30]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = [(1,2), (3,4), (5,6)]\n",
    "list(map(lambda item: item[0]*item[1], items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we sometimes use `lambda` and `map`? Because, as you see in the example above, they make your code really concise by combining 3 lines of code to 1 line.\n",
    "\n",
    "Besides `map`, there is also **`filter`** that selectively returns elements in an array according to whether you return `True`. There is also **`reduce`** that performs computation on a list of items then returns result.\n",
    "\n",
    "Here is a [good tutorial](http://book.pythontips.com/en/latest/map_filter.html) about `map`, `filter`, and `reduce`. Read it if you are not familiar with how they are used. Then proceed to the next cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, use `filter` and `lambda` to return a list that contains positive numbers only. The output should be:\n",
    "\n",
    "```[1, 4, 5]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 0, 5]\n"
     ]
    }
   ],
   "source": [
    "numbers = [1, 4, -1, -100, 0, 5, -99]\n",
    "only_pos=list(filter(lambda x: x>=0, numbers))\n",
    "print(only_pos)\n",
    "# Enter your code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use `reduce` and `lambda` to return a string that only contains English terms. The English terms are separated with a whitespace ` `.\n",
    "\n",
    "Hints: \n",
    "\n",
    "* If your Jupyter Notebook cannot import `langdetect`, you need to install it with `pip install langdetect`. If Jupyter Notebook still cannot find the library, try install with `python3 -m pip install langdetect`. This is because you need to install `langdetect` in the same Python run environment where Jupyter Notebook is running.\n",
    "\n",
    "* If a word is English, `langdetect.detect(word)=='en'` will return `True`.\n",
    "\n",
    "Your output should read:\n",
    "\n",
    "```'good morning everyone'```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  how langdetect works is not stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['everyone']\n",
      "['доброго', 'каждый']\n",
      "everyone\n",
      "доброго каждый\n"
     ]
    }
   ],
   "source": [
    "import langdetect\n",
    "from functools import reduce\n",
    "words = ['good morning', '早上好', 'доброго', 'おはようございます', 'everyone', '大家', 'каждый', 'みんな']\n",
    "\n",
    "english=[]\n",
    "russian=[]\n",
    "\n",
    "for word in words:\n",
    "    if langdetect.detect(word)=='en':\n",
    "        english.append(word)\n",
    "    elif langdetect.detect(word)=='ru':\n",
    "        russian.append(word)\n",
    "print(english)\n",
    "print(russian)\n",
    "\n",
    "en=reduce(lambda x, y: x + \" \" + y, english)\n",
    "print(en)\n",
    "ru=reduce(lambda x, y: x + \" \" + y, russian)\n",
    "print(ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good morning USA', ' we said to everyone']\n",
      "['каждый день замечетелен']\n",
      "['おはようございます', 'みんな']\n",
      "['bleiben wir heute zu hause', 'möglicherweise']\n",
      "good morning USA  we said to everyone\n",
      "каждый день замечетелен\n",
      "おはようございます - - みんな\n",
      "bleiben wir heute zu hause - - möglicherweise\n"
     ]
    }
   ],
   "source": [
    "from langdetect import DetectorFactory \n",
    "DetectorFactory.seed = 0 \n",
    "\n",
    "from functools import reduce\n",
    "words = ['good morning USA', '早上好', 'доброго утра друзья', 'おはようございます', ' we said to everyone', '大家', 'каждый день замечетелен', 'みんな', 'bleiben wir heute zu hause', \"möglicherweise\"]\n",
    "\n",
    "english=[word for word in words if langdetect.detect(word)=='en']\n",
    "russian=[word for word in words if langdetect.detect(word)=='ru']\n",
    "japonais=[word for word in words if langdetect.detect(word)=='ja']\n",
    "deutsch=[word for word in words if langdetect.detect(word)=='de']\n",
    "\n",
    "print(english)\n",
    "print(russian)\n",
    "print(japonais)\n",
    "print(deutsch)\n",
    "\n",
    "en=reduce(lambda x, y: x + \" \" + y, english)\n",
    "print(en)\n",
    "ru=reduce(lambda x, y: x + \" \" + y, russian)\n",
    "print(ru)\n",
    "jp=reduce(lambda x, y: x + \" - - \" + y, japonais)\n",
    "print(jp)\n",
    "de=reduce(lambda x, y: x + \" - - \" + y, deutsch)\n",
    "print(de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"NOTE\n",
    "\n",
    "Language detection algorithm is non-deterministic, \n",
    "which means that if you try to run it on a text which is either too short or too ambiguous, \n",
    "you might get different results everytime you run it.\n",
    "\n",
    "To enforce consistent results, call following code before the first language detection:\n",
    "\n",
    "`python from langdetect import DetectorFactory DetectorFactory.seed = 0 `\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce()\n",
    "reduce() est plus tordu. La fonction doit prendre deux paramètres en entrée, et retourner une valeur.\n",
    "Au premier appel, les deux premiers éléments de l’itérable sont passés en paramètres.\n",
    "Ensuite, le résultat de cet appel et l’élément suivant sont passés en paramètre, et ainsi de suite.\n",
    "Vous n’avez rien pigé ? C’est normal. reduce() est parfaitement cryptique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrée : 2 3\n",
      "Sortie : 2 3\n",
      "Entrée : (2, 3) 4\n",
      "Sortie : (2, 3) 4\n",
      "Résultat final ((2, 3), 4)\n"
     ]
    }
   ],
   "source": [
    "def afficher(a, b):\n",
    "    print(\"Entrée :\", a, b)\n",
    "    print(\"Sortie :\", a , b)\n",
    "    return a ,b\n",
    " \n",
    "res = reduce(afficher, range(2,5))\n",
    "print(\"Résultat final\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if you still have time, convert your response in Q2 by using `lambda`, `map`, `filter`, or `reduce` where applicable. Enter your function in the cell below.\n",
    "As you write Python functions, generally you don't want to make your function too long. Long functions are difficult to read and difficult to debug. If a function is getting too long, consider breaking it into sever shorter functions where the main function calls other functions. If anything goes wrong, you can output debug messages in each of the functions to check where exactly the error is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Enter your code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your function below with the Bag of Words lab docs (it's easier for you to debug your code). Your output should be:\n",
    "\n",
    "```{'bag_of_words': ['ironhack', 'cool', 'love', 'student'], 'term_freq': [[1, 1, 0, 0], [1, 0, 1, 0], [1, 0, 0, 1]]}```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_bow_from_docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f81ffd973364>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m bow = get_bow_from_docs([\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;34m'../../lab-bag-of-words/your-code/doc1.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;34m'../../lab-bag-of-words/your-code/doc2.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     '../../lab-bag-of-words/your-code/doc3.txt'],\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_bow_from_docs' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import stop_words\n",
    "bow = get_bow_from_docs([\n",
    "    '../../lab-bag-of-words/your-code/doc1.txt', \n",
    "    '../../lab-bag-of-words/your-code/doc2.txt', \n",
    "    '../../lab-bag-of-words/your-code/doc3.txt'],\n",
    "    stop_words.ENGLISH_STOP_WORDS\n",
    ")\n",
    "\n",
    "\n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
